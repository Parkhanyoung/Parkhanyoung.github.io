[ { "title": "common js 순환참조", "url": "/posts/JS%EC%88%9C%ED%99%98%EC%B0%B8%EC%A1%B0/", "categories": "삽질을의미있게, js", "tags": "삽질, commonjs, node, 순환참조", "date": "2021-12-29 01:00:00 +0900", "snippet": "문제 상황React 강의를 들으며 웹앱을 구현하던 도중, export(import)가 정상적으로 되지 않는 문제가 발생했다. 문법을 올바르게 썼음에도 불구하고 자꾸 빈 객체만 import 되었다. 강의에 나온 코드 그대로 따라쳤으면 좋았으련만, 나는 es6가 아닌 commonjs를 써보겠다고 혼자 다른 코드를 작성하고 있었기 때문에 문제를 쉽사리 해결할 수 없었다.세부 사항1. 상황TicTacToe.jsx에서 CLICK_CELL이라는 상수를 내보내어, Td.jsx라는 동일 경로의 다른 파일에서 그 상수를 받아 오려 한다. 그런데 예상과 달리 빈 객체가 required 되어 CLICK_CELL의 값이 undefined로 나타난다. [해당 상수는 Td.jsx가 아닌 다른 경로에 있는 파일에서는 정상적으로 required 된다.]2. 코드파일 구조 TicTacToe.jsx Td.jsx 3. 추측common js 방식으로 같은 경로에 있는 모듈을 받아오면 문제가 발생한다.해답일단 내 추측은 틀렸다. 이 문제는 순환참조로 인한 문제였다. TicTacToe.jsx에서 Td.jsx를 참조하고 있는데, Td.jsx에서 다시 TicTacToe.jsx를 참조하니 순환참조가 발생한 것이다. common js에서는 이러한 순환참조가 발생할 경우, 무한 반복을 막기 위해 의도적으로 빈 객체를 반환한다. 이를 해결하기 위해, 1) 다른 모듈을 참조하지 않은 독자적인 모듈을 만들어서 사용한다. 2) madge라는 라이브러리를 통해 참조 관계를 시각화하여 파악한 뒤, 코드를 수정한다. 3) 웹팩 플러그인 중 circular-dependency-plugin을 활용할 수도 있다.공부 자료 [resilient-923]: [javascript] 순환참조란? [김정환 블로그]: 순환 참조" }, { "title": "2021년을 돌아보며", "url": "/posts/%ED%9A%8C%EA%B3%A02021/", "categories": "회고, 2021년", "tags": "2021년, 2022년, 연말, 회고", "date": "2021-12-25 01:00:00 +0900", "snippet": "Good Bye 2021어느덧 크리스마스, 이제는 정들었던 2021년을 보내줄 때가 왔다. 올해는 나에게 여러모로 의미가 깊은 해였다. 전역을 해서 사회로 복귀한 해이고, 어느 때보다 주도적인 태도로 살았던 해이며, 무엇보다 프로그래밍에 대한 흥미를 발견할 수 있었던 해이다. 많은 일들이 있었고 그 일들은 나에게 많은 변화를 가져왔다. 훗날 돌아봤을 때, 올해가 전환점이었다고 생각하는 순간이 분명 있을 것이라고 예상할 만큼, 성격 면에서도, 태도 면에서도, 그리고 진로 면에서도 큰 변화가 있었다. 성인이 된 이후에는, 내가 직접 결정할 수 있는 범위가 넓어지니 시간의 무게, 선택의 무게가 다르게 느껴진다. 단 하루가 이후 십년을 바꿀 수 있으며, 단 하나의 선택이 평생에 영향을 줄 수 있다는 사실을 몸소 깨달아가고 있다. 이 글을 통해 올 한 해가 나를 어떻게 바꾸었는지 돌아보고 기록으로 남기고자 한다.월별 회고1, 2월 나에게 1월은 전역의 달이었다. 전역했다는 사실에 들떠 불타는 열정을 주체하지 못하던 시기였다. 1, 2월 두 달 간은 누구보다도 바람직한 생활 패턴을 유지했다. 아침 일찍 일어나 스트레칭을 하고, 영어 회화를 공부했다. 그 후, 독서 및 글쓰기를 하고 학원 아르바이트에 다녀온 후, 진로에 대해 고민하는 시간을 가졌다. 이때까지만 해도 나의 희망 진로는 카피라이터, 혹은 마케터였기에 그와 관련된 자료들을 열심히 찾아보았다. 또, 2월 중순 쯤에는 군대에서 찜해두었던 교내 마케팅 학회에 지원도 해보았지만, 아쉽게 2차 면접에서 떨어졌다. 이외에도 그동안 만나지 못했던 친구들을 열심히 만나러 다녔으며 운동도 꾸준하게 했다. 1, 2월을 요약하자면, 군대 내에서의 훌륭한 생활 패턴과 건강한 다짐을 사회에서 실천하기 위해 부단히 노력했던 시기였다고 할 수 있다. 아마 주위에서 전역 후의 그 열정은 금방 식을 것이라고 단언하던 게 자극이 되었던 것 같다(돌아보니 그 말이 어느 정도 사실이었다 ㅎㅎ). 지금 생각해보면 이 시기의 열정은 주체적이기보다는 관성에 의한 것이었던 것 같다.3월 3월은 웹 프로그래밍 학회인 ‘멋쟁이사자처럼(멋사)’에 들어갔던 시기로, 이때부터 많은 변화가 생겼다. 우선 멋사에 들어가게 된 계기는 큰 게 아니었다. 창업을 꼭 해보아야 한다는 조언을 자주 들었었고, 익숙하지 않은 새로운 것을 배우고 싶었기 때문에 과감하게 지원했다. 마침 앞서 마케팅 학회에서 한 번 떨어진 경험이 있었기에 더 잃을 게 없다는 마인드로 더욱 과감하게 지원서를 냈던 것 같다. 내가 멋사 회원 모집 공고를 본 것은 공교롭게도 모집 마지막 날이었다. 당일 학원 아르바이트 일정도 있었기 때문에 5시간 남짓한 시간에 2천 자나 되는 지원서를 쓰는 것이 가능할까 의문이 들기도 했었다. 하지만 다행히도 마케팅 학회를 지원할 때 써둔 지원서를 참고할 수 있었고, 당시의 나는 글쓰기를 꾸준하게 해왔던 터라 빠르게 새로운 지원서를 완성할 수 있었다. 기회는 준비된 자에게 온다는 말의 의미를 실감할 수 있었다. 그렇게 우연의 우연을 거듭하여 들어간 멋사에서 접하게 된 코딩의 첫인상은 흥미롭기보다는 무서웠다. 프로그래밍 언어라고 할 수도 없는 HTML이었음에도, 코딩의 c자도 모르던 나에게는 어렵게 느껴졌다. 개발자 도구로 네이버 웹페이지의 글자를 바꾸는 것만으로도 마냥 신기했었다. 이후에는 css를 배워 인스타그램, 트위터 클론코딩을 했다. 물론 겉모습뿐이었지만, 내 코드가 웹페이지로 형상화되는 것이 신기하게 느껴졌다. 아마 이때부터 웹 개발에 흥미를 가지기 시작했던 것 같다.4월 4월엔 파이썬과 장고를 배우기 시작했다. codecademy라는 외국 사이트를 통해 파이썬을 공부했는데, 기본적인 연산자, 자료형 등의 기본 개념조차 없는 상태에서 영어로 배우려니 더욱 헷갈렸다. 그 후엔 웹에 대해 아무것도 모른 채 장고를 배우게 됐는데 정말 어려웠다. 파이썬도 익숙하지 않은 상태에서 웹 프레임워크까지 더해지니 벅차게 느껴졌다. 그래도 매주 세션 내용을 꼭 이해하고 넘어가려는 고집은 있었어서 매주 세션 내용 이해를 나중으로 미루거나 포기하지는 않았다. 이를 위해서 세션을 들을 때는 코드를 따라 쳐보는 파트가 있어도 따라치지 않고 운영진분들께 매달려 질문했던 것 같다. 이해만 하면 코드는 집에 가서 얼마든 칠 수 있으니 당장은 운영진분들의 도움을 최대한 받자는 마인드였다. 친절하게 질문을 받아주신 운영진분들께 참 감사했다. 4월을 기점으로 코딩을 생활화하기 시작했다. 학원 아르바이트도 그만 두었고, 약속도 많이 줄이고 학회 활동과 코딩 공부에 충실히 임했다. 물론 한 달 남짓한 시간에 얼마나 잘하게 되었겠냐마는, 적어도 더 이상 코딩이 마냥 어렵게만 느껴지지는 않았다. 이전까지는 오르지 못할 산처럼 느껴졌다면, 이때부턴 도전해보고 싶다는 생각이 들기 시작했다.5월 5월은 계속해서 장고에 대해 공부했다. 과제로 간단한 웹사이트를 만들어보며 장고 사용법에 익숙해져갔다. MTV 패턴, ORM, manage.py 등 각각이 무엇인지는 몰라도, 간단하게 활용할 수는 있게 되었다. 그러다가 5월 중순이 지나서는 그 다음주에 있을 멋사 해커톤을 위한 아이디어톤을 했다. 아이디어톤에서 처음으로 기획이라는 것을 경험해볼 수 있었다. BM, 시장 규모 등 사업화에 관한 요소들까지는 미처 고려하지 못했지만, 사람들에게 필요할 만한 서비스가 무엇일지, 그 서비스를 어떻게 더 매력적인 서비스로 발전시킬지 고민해보는 과정만으로도 충분히 의미 있었다고 생각한다. 이때를 기점으로 웹 서비스를 사용자가 아닌 생산자의 관점에서 어느 정도 바라볼 수 있게 된 것 같다. 사용자로서는 자연스럽고 당연하게만 느껴지던 인스타그램, 유튜브, 네이버 등 대규모 웹 서비스의 UX/UI가 결코 당연한 것이 아니었음을 깨달을 수 있었다. 아이디어톤 결과, 우리 조는 비대면 강의 대리 출석 및 녹화 서비스를 만들기로 결정했다. 물론 이 서비스를 실제로 사용하거나 상용화할 생각은 없었고, 그 당시 많은 학생들이 바랐을 것이라고 생각했으며 아이디어 자체가 재밌게 느껴져서 선택했다. 게시판 정도의 간단한 웹만 구현해봤었던 나로서는, 출석이나 녹화를 코딩으로 자동화할 수 있다는 것이 마치 마법처럼 느껴졌던 것 같다. 그리하여 selenium, beautifulsoup 등을 이용하여 서비스를 구현했다. 아쉽게도 해커톤 당일에 서비스를 모두 구현하는 것에는 실패하여 시연해보이지는 못했다. 그래도 CRUD가 아닌 자동화라는 새로운 기능을 구현해본 경험이 프로그래밍 공부에 큰 동기부여가 됐다. 또한 해커톤을 통해 처음으로 협업을 경험해볼 수 있었다(물론 깃헙이 아닌 카카오톡을 주로 이용했다..ㅎ ).6월 6월은 기말고사의 달이자 종강의 달이었다. 잠시 프로그래밍 공부는 미뤄두고 학교 공부를 했다. 학교 공부를 하며 다시금 프로그래밍이 적성에 맞는다는 사실을 확인할 수 있었다.7월, 8월 7, 8월은 방학을 한 후, 프로젝트에 몰두한 시기였다. 총 두 가지 프로젝트에 참여했다. 하나는 고대생 연대생 통화 매칭 서비스였고, 다른 하나는 현직자 멘토링 서비스였다. 둘 모두, 장고 풀스택 + 바닐라 자바스크립트로 개발됐으며 나는 백엔드를 맡았다. 두 프로젝트의 팀원들 모두 개발 경험이 많지 않은 개발 꿈나무들이었다. 개발을 리드해주는 사람이 없어 개발 진행 속도는 조금 더뎠지만, 시행착오를 거친 만큼 단발성이 아닌 체화된 지식을 얻을 수 있었다. 구글링 실력도 많이 향상되었다. 이때를 기점으로 장고와 제법 친해진 것 같다. 또한 두 프로젝트를 하는 동안 처음으로 AWS와 NGINX를 써보기도 했다. 전부 알고 활용한 것은 아니지만, 공부하는 과정에서 인프라 및 웹서버에 대해 조금이나마 감을 잡을 수 있었다. 개발 외에 기획에도 열심히 참여했다. 이때는 해커톤 프로젝트에 비해 기획이 체계적으로 진행됐다. BM, 시장규모, 확장 방향 등에 대해서도 같이 고민해보고 답을 찾으려 노력했다. 물론 미숙한 점이 많았고, 결과적으로 수익을 만들지는 못했다. 그래도 통화 매칭 서비스에서는 200명 정도의 유저가 모였으며, 실제로 통화가 이루어지기도 했다. 내가 구현했던 친구 신청 및 쪽지 기능이 활발히 쓰이는 것도 볼 수 있었다. 현직자 멘토링 서비스는 유저가 서비스를 실제로 이용하지는 않았지만(아마 유료여서 유저들이 쉽게 사용하지 못했던 것 같다), 개발뿐만 아니라 프로젝트 과정 전반에 참여하며 시야를 넓힐 수 있었다. 이처럼 7월과 8월에는 처음으로 배포 및 수익을 위해 웹 애플리케이션을 만들어보았다. 내가 제작에 참여한 서비스가 실제 유저에 의해 사용되는 것을 보니 크게 동기부여가 되었다. 웹 프로그래밍에 본격적으로 흥미를 붙이게 된 시기였다.키워드별 회고 개발 성향(인간관계 포함) 가치관 문제점 잘한점 내년 각오 및 자세" }, { "title": "useMemo, useCallback, useRef", "url": "/posts/useMemo/", "categories": "Web, React", "tags": "web, front-end, react, hooks, useMemo", "date": "2021-12-24 01:00:00 +0900", "snippet": "useMemo, useCallback, useRefuseMemo주로 복잡한 함수에 의해 산출되는 특정 값을 기억해뒀다가 재활용하기 위해 사용한다. 로또추첨기 함수형 컴포넌트에서 로또 번호를 뽑는 getWinNumbers가 매 렌더링마다 실행이 되었다(함수형 컴포넌트는 리렌더될 때마다 컴포넌트 함수 전체 실행되기 때문). 만약 getWinNumbers가 10초씩 걸리는 로직이었다면, state에 변화가 있을 때마다(리렌더될 때마다) 10초씩 지연됐을 것이다. 이러한 불상사를 막기 위해 useMemo가 존재한다. useMemo로 등록한 값은 캐싱되어, 두번째 인자로 넘긴 배열 속 아이템에 변화가 생기지 않는 한, 캐싱된 값을 재활용한다. useMemo 덕분에 getWinNumbers는 최초 렌더 시와 한번더 버튼을 누를 때만 실행되게 됐다. 이처럼 useMemo는 어떠한 변수값이 복잡한 함수에 의해 산출되는 경우, 그 변수값을 캐싱해서 사용하여 그 함수가 재실행되는 횟수를 최대한 줄이기 위해 활용한다.useCallback함수형 컴포넌트는 렌더 시마다 전체가 재실행되기 때문에 컴포넌트 내에 선언된 함수가 반복적으로 새로 만들어진다. 만약 함수가 전혀 변하지 않았는데, 그 함수를 다시 생성한다면 그것은 낭비가 될 것이다. 그렇기 떄문에 useCallback을 사용하여 함수를 캐싱한다. useCallback을 사용하면 두번째 인자로 넘겨준 배열의 요소가 변하지 않는 한 캐싱된 함수를 활용한다. 만약 state값에 따라 함수의 내용이 변한다면 그 state값을 두번째 인자의 배열에 넣어주면 필요할 때만 함수를 생성할 수 있다. *특히 자식 컴포넌트에 함수를 넘겨주는 경우에는 useCallback을 필히 사용해야 한다. 왜냐하면 useCallback을 사용하지 않으면, 부모 컴포넌트가 렌더링 될 때마다 자식 컴포넌트에 새롭게 생성한 함수를 넘길 것이며, 자식 컴포넌트는 그것을 props 중 하나가 변한 것으로 인지하여 리렌더할 것이기 때문이다(memo를 사용했다고 하더라도).useMemo vs useRefuseMemo와 useRef 모두 특정 값을 기억해두기 위해, 혹은 변수에 담아두기 위해 사용한다는 측면에서 두 가지가 혼동될 수 있다. 이 두 가지가 헷갈릴 때는 각 메소드의 목적을 생각해보면 쉽게 구별할 수 있다. 먼저 useMemo는 앞서 말했듯 복잡한 함수에 의해 산출되는 특정 값을 캐싱해 사용함으로써 성능을 개선하기 위해 사용한다. 그에 반해 useRef는 state로 관리될 필요가 없는 특정 값을 컴포넌트 내에서 활용하거나 DOM을 조작하기 위해 사용한다. Memo는 캐싱하여 성능을 개선하기 위한 목적이고, ref는 특정 값을 다른 곳에서 참조하기 위한 목적이다.useMemo vs useCallbackuseMemo와 useCallback 모두 성능 개선을 위해 캐싱하기 위해 사용된다는 측면에서 두 가지가 혼동될 수 있다. 이 두 가지가 헷갈릴 때는 각 메소드가 기억하는 대상을 생각해보면 쉽게 구별할 수 있다. useMemo는 함수의 산출값을 기억하는 반면, useCallback은 함수 자체를 기억한다.함수형 컴포넌트 성능 개선 Tip함수형 컴포넌트는 state가 바뀔 때마다(리렌더될 때마다) 컴포넌트 함수 전체가 실행된다. 그렇기 때문에 불필요하게 함수가 중복 실행되는 경우가 빈번히 발생한다. 이를 방지하기 위해서는 각 함수에(복잡한 함수면 필수!) console.log(‘함수명’)을 넣어두어 함수들이 정말 필요할 때만 실행되는 것이 맞는지 확인해주는 것이 좋다. 그리고 만약 불필요하게 중복 실행되는 함수가 있다면, 그것은 개선의 여지가 있다는 것이므로 useEffect, useMemo 등을 활용하여 개선한다.공부 자료 [제로초 유튜브]: useMemo와 useCallback" }, { "title": "componentDidMount, componentWillUnmount !== useEffect", "url": "/posts/CDM,CWUvsuseEffect/", "categories": "Web, React", "tags": "web, front-end, react, lifecycle, component", "date": "2021-12-22 01:00:00 +0900", "snippet": "componentDidMount / componentWillUnmount와 useEffect흔히 클래스형 컴포넌트에서의 componentDidMount와 componentWillUnmount가 함수형 컴포넌트에서의 useEffect에 대응된다고 한다. 하지만 그것은 반은 맞고 반은 틀린 소리이다. 그 이유는 클래스형 컴포넌트는 관리하는 state 값이 변화할 경우, render 메소드만 실행되지만, 함수형 컴포넌트는 기존의 컴포넌트가 언마운트되고 함수 전체가 다시 실행되어 다르게 동작하기 때문이다. 예시를 들어보겠다.const React = require(&#39;react&#39;);const { useState, useEffect, useRef } = React;const [imgNumber, setImgNumber] = useState(1); const numbers = { 가위: 1, 바위: 2, 보: 3}const changeHand = () =&amp;gt; { if (imgNumber === numbers.가위) { setImgNumber(numbers.바위); } else if (imgNumber === numbers.바위) { setImgNumber(numbers.보); } else if (imgNumber === numbers.보) { setImgNumber(numbers.가위); }};useEffect(() =&amp;gt; { setInterval(changeHand, 1000); return () =&amp;gt; { clearInterval(intervalRef.current); }}, [imgNumber]);위의 코드는 1000ms 간격을 두고 가위, 바위, 보 이미지가 지속적으로 번갈아 나오는 코드 중 일부이다. state로 관리하고 있는 imgNumber 값에 따라 가위, 바위, 보 중 하나의 이미지가 나타나는데, 1000ms 간격으로 imgNumber값이 바뀌면서 그에 따라 화면에 나타나는 이미지도 바뀌는 원리이다.setInterval은 한 번 실행하면 일정 시간 간격을 두고 지속적으로 실행되는 비동기 함수이다. 그렇기 때문에 이 상황에서는 componentDidMount에 대응되는 ‘useEffect + 빈배열’을 이용하면 된다고 생각하기 쉽다. 처음 렌더될 때 setInterval이 실행되면 그 이후로 시간 간격을 두고 state값이 변경되는 코드가 지속적으로 실행될 것이니 말이다. 하지만 여기서 ‘useEffect + 빈배열’을 이용하면 가위에서 바위로 딱 한 번만 바뀌고 멈춘다. 왜 그럴까? 그것은 앞에서 말했듯이, 함수형 컴포넌트는 state값이 바뀔 때마다 함수 전체가 재실행되기 때문이다. useEffect 내부에 state 값을 변경하는 setImgNumber가 있기 때문에, 첫 렌더 직후 실행된 setImgNumber에 의해 imgNumber라는 state의 값이 바뀌게 되고, 그에 따라 기존의 컴포넌트가 언마운트되고 컴포넌트 전체 함수가 재실행된다. 그리고 그때 첫 렌더 시에만 실행되는 useEffect 내부의 함수는 다시 실행되지 않게 된다. 이것이 ‘useEffect + 빈배열’을 사용하면 이미지가 가위에서 바위로 딱 한 번만 변하는 이유이다.조금 더 자세히 설명하자면, 정상 작동을 하기 위해서는 위의 코드처럼 1)useEffect 두번째 인자로 넘기는 배열에 imgNumber를 넣어주고, 2)cleanup 메소드로 setInterval을 취소해야 한다. 그 이유는, 1) 함수형 컴포넌트에서는 state(imgNumber)가 바뀔 때마다 컴포넌트가 언마운트되어 setInterval이 setTimeout과 동일한 동작을 보이게 되므로 imgNumber가 바뀔 때마다 changeHand 함수를 다시 실행해주어야 하기 때문이며, 2) cleanup 메소드를 설정하지 않으면 모든 state값 중 하나라도 바뀔 때마다 setInterval이 하나씩 쌓여서 이미지 변화 속도가 점점 빨라지기 때문이다. [물론 바꾼 코드조차도, 강의 내용 중 클래스형 컴포넌트의 원래 모습을 유지한 채 함수형 컴포넌트로 바꾸는 과정에서 나타난 것이므로 효율적인 코드는 결코 아니다.]이러한 특성 때문에 useEffect 내부에서 state 값을 변경하는 경우, 그리고 비동기 함수를 사용하는 경우에는 주의를 기울여야 한다. 클래스형 컴포넌트의 라이프 사이클 메소드와 일대일로 대응된다고 생각했다가는 큰 코를 다칠 수 있다.요약 hooks를 클래스 컴포넌트의 라이프 사이클 메소드와 일대일로 대응시키는 오류를 범해선 안 된다. 클래스형 컴포넌트는 state 값이 변화할 때마다, 기존의 컴포넌트가 언마운트됨과 동시에 컴포넌트 전체 함수가 다시 실행된다.공부 자료 [제로초 유튜브]: Hooks와 useEffect [벨로퍼트]: 16. useEffect를 사용하여 마운트/언마운트/업데이트시 할 작업 설정하기" }, { "title": "React Lifecycle", "url": "/posts/ReactLifecycle/", "categories": "Web, React", "tags": "web, front-end, react, lifecycle, component", "date": "2021-12-21 01:00:00 +0900", "snippet": "React 라이프 사이클라이프 사이클이란 ‘태어나서 죽을 때까지의 과정, 혹은 순서’를 말한다. 리액트의 컴포넌트에게도 라이프 사이클(수명 주기)이 존재한다. 컴포넌트의 라이프 사이클은 ‘페이지에 렌더되기 이전의 준비’로부터 시작되어 ‘페이지에서 사라질 때’ 끝이 난다. 리액트 사용자는 각 컴포넌트의 라이프 사이클 사이사이에 개입하여 특정 동작이 수행되도록 조작할 수 있다. 원하는 결과를 얻기 위해서는 라이프 사이클 중 어느 단계에 개입할지 결정하는 것이 매우 중요하다. 따라서 우리는 컴포넌트의 라이프 사이클을 잘 알 필요가 있다.컴포넌트 라이프 사이클 메소드라이프 사이클은 총 9단계로 구성되고 라이프 사이클 메소드는 클래스형 컴포넌트에서만 활용가능하며, 함수형 컴포넌트(hooks 사용)에도 각 메소드에 대응되는 구현 방법이 존재한다. 세부 사항은 다음과 같다. 1. constructor(hooks: useState): 컴포넌트가 만들어질 때 처음으로 호출된다. 이때 초기 state가 정해진다. 2. getDerivedStateFromProps(hooks: 사용법): 컴포넌트가 마운트될 때, 혹은 업데이트될 때 호출된다. props로 받은 값을 state에 동기화한다. 자주 쓰이지는 않는 메소드이다. 3. shouldComponentUpdate(hooks: React.memo(props), useMemo(state)): prop나 state를 변경했을 때, 리렌더링을 할지 말지 결정하는 메소드이다. 반환값은 true, 혹은 false이다. 이 메소드는 성능 최적화만을 위한 것이며, 다른 목적으로 사용했을 시 버그로 이어질 수 있다. 클래스 형에서도 이 메소드보다는 PureComponent를 더 많이 사용한다. 4. render(hooks: 불필요(just return)): 컴포넌트를 렌더한다. 가장 기초적이면서 중요한 메소드이다. 5. getSnapshotBeforeUpdate(hooks: 없음): 렌더링을 통해 만들어진 결과가 브라우저(DOM)에 실제로 반영되기 직전에 호출되며, 변화 적용 이전 props, state 정보를 가져올 수 있다. 또한 이 메소드의 리턴값은 componentDidUpdate의 3번째 파라미터로 넘겨진다. 요소 추가 시에도 스크롤 위치 유지 등에 활용되며, 자주 쓰이지는 않는 메소드이다. 6. componentDidMount(hooks: useEffect + 빈 의존성 배열): 최초 렌더링 이후 호출된다. 컴포넌트가 화면에 표시된 이후에 호출되는 것이다. 업데이트로 인한 리렌더링 시에는 호출되지 않는다. 주로 이 메소드를 통해 setInterval과 같은 비동기 요청을 처리한다. 여기서 구현된 비동기 요청 중 컴포넌트 unmount 직전까지 완료되지 않은 요청은 componentWillUnmount 메소드를 이용하여 정리해주어야 한다. 그렇지 않으면 컴포넌트가 unmount된 이후에도 비동기 요청이 콜스택에 남아 메모리 누수의 원인이 된다. 7. componentDidUpdate(hooks: useEffect): 리렌더링 이후 호출된다. 업데이트 직후이므로, DOM 관련 조작이 가능하다. 8. componentWillUnmount(hooks: useEffect CleanUp 메소드): 컴포넌트를 DOM에서 제거할 때 호출된다. componentDidMount에서 등록한 비동기 이벤트가 있다면 메모리 누수 방지를 위해 여기서 제거해줘야 한다. componentDidMount와 쌍으로 활용되는 경우가 많다. 9. componentDidCatch(hooks: 없음): 컴포넌트 렌더링 도중 에러가 발생했을 경우 호출된다. 오류 발생 시 앱을 멈추지 않고, 오류 UI를 보여주기 위해 사용한다.공부 자료 [kyun2dat 개인 블로그] 리액트 라이프사이클의 이해 [velopert 개인 블로그] 누구든지 하는 리액트 5편(LifeCycle API)" }, { "title": "PyCon - Pythonic code가 과연 효율적일까?", "url": "/posts/Pythonic/", "categories": "Better Code, Python", "tags": "pycon, pythonic", "date": "2021-12-18 01:00:00 +0900", "snippet": "Pythonic Code가 효율적일까?python의 철학 요약: 간단한 게 복잡한 것보다 낫다. 가장 아름다운 하나의 답이 존재한다.Pythonic?Pythonic은 말 그대로 파이썬답다는 뜻이다. 그리고 파이썬답다는 것은 파이썬의 기능들을 잘 이용하여 간결하고 가독성이 좋다는 것이다. 보통 파이썬 커뮤니티의 사람들이 쓰는 패턴을 Pythonic 코드라고 생각한다. Pythonic하지 않는 코드라고 하면, Java나 C 등 다른 언어의 형식으로 쓰인 파이썬 코드일 것이다. Pythonic한 코드는 PEP 8을 잘 따름으로써 작성할 수 있다. 수고를 들여 Pythonic한 코드를 작성한다면 가독성도 좋아지고, 유지보수도 한결 쉬워질 것이다.파이썬에서는 하나의 기능을 구현하기 위해 여러 가지 문법을 이용할 수 있는 경우가 있다. 이때 pythonic한 방법이 성능 상으로도 더 유리한지 비교해보자.기능 별 비교List 만들기def list_comprehension(x): result = [i*i for i in range(x)] return resultdef list_append(x): result = [] for i in range(x): result.append(i*i) return resultdef list_extend(x): result = [] result.extend(i*i for i in range(x)) return resultCPU time: List Comprehension이 다른 두 가지에 비해 빠르다.Dictionary 합치기def for_loop(d_1, d_2): result = {} for k in d_1: result[k] = d_1[k] for k in d_2: result[k] = d_2[k] return resultdef update_method(d_1, d_2): result = {} result.update(d_1) result.update(d_2) return resultdef dict_comprehension(d_1, d_2): result = {k: v for d in [d_1, d_2] for k, v in d.items()} return resultdef dict_kwargs(d_1, d_2): result = {**d_1, **d_2} return resultCPU time: pythonic한 방법인 Update와 Kwarg가 가장 빠르다.콜렉션 내 아이템 찾기def find_in_set(s, x): return x in sdef find_in_list(l, x): return x in ldef find_in_tuple(t, x): return x in tCPU time: set이 가장 빠르다. *set은 해쉬테이블을 사용하기에 요소들을 일일이 순회할 필요가 없어 빠르다. 하지만 set은 만드는 데 비용이 많이 들기에, 컬렉션이 작거나 아이템을 많이 찾지 않는다면 list나 tuple을 이용하는 것이 좋다.String formattingdef percentage_formatted_string(n): return [&quot;%d&quot; % i for i in range(n)]def formatted_string(n): return [&quot;{i}&quot;.format(i=i) for i in range(n)]def f_string(n): return [f&#39;{i}&#39; for i in range(n)]CPU time: f string이 압도적으로 빠르고, format이 가장 느리다. *format은 CALL_FUNCTION에 의해 일어나서 overhead가 큰데 반해, f string은 하나의 표현법에 불과하므로 비용이 작다.Slotsclass ImmutableThing: __slots__ = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] def __init__(self, a, b, c, d): self.a = a self.b = b self.c = c self.d = dclass MutableThing: def __init__(self, a, b, c, d): self.a = a self.b = b self.c = c self.d = d# 똑같은 object를 n개 만드는 함수@memory_profiler.profile(precision=4)def add_in_immutablething(n): data = [ImmutableThing(1, 2, 3, 4) for _ in range(n)] return data@memory_profiler.profile(precision=4)def add_in_mutablething(n): data = [MutableThing(1, 2, 3, 4) for _ in range(n)] return dataMemory: Slots가 압도적으로 메모리 사용량이 적다.결론비슷해 보이는 문법들 사이에도 성능 차이가 존재한다. 아무리 비슷해보여도 각 문법을 써야하는 곳이 정해져 있다. 자신에게 익숙한 문법만 고집하기보다는 새로운 문법, 혹은 익숙하지 않은 문법도 알아보는 것이 좋다. 특히 습관이 될 수 있는 간단한 문법들은 더더욱 신경쓰는 것이 좋다.공부 자료 [PyCon 안주은] Pythonic code가 과연 효율적일까?: https://www.youtube.com/watch?v=Txz7K6Zc-_M [codechacha] Pythonic은 무엇인가?: https://codechacha.com/ko/pythonic-and-pep8/" }, { "title": "PyCon - Django vs Flask", "url": "/posts/DjangoVSFlask/", "categories": "Web, Django", "tags": "pycon, django, flask, web framework", "date": "2021-12-17 01:00:00 +0900", "snippet": "Django vs Flask웹 프레임워크?웹: 인터넷 상 연결된 컴퓨터들 간에 정보를 공유할 수 있는 전세계적 정보 공간. 프레임워크: 특정 종류의 소프트웨어를 개발할 때 같은 작업을 반복하지 않을 수 있도록, 필수적으로 거쳐야 하는 과정들을 우아하게 해결해 놓은 도구(클래스, 라이브러리)들의 모음, 혹은 그 구조.웹을 구현하기 위해서는 생각보다 많은 작업이 필요하다. HTTP 요청 처리, URL 파싱, 보안 관련 처리, DB 관련 작업 등등 셀 수 없이 많다. 이러한 작업을 일일이 구현한다면 시간이 엄청나게 오래 걸릴 뿐만 아니라, 완성도도 심각하게 안 좋을 것이다. 그리하여 사용자가 웹의 내용적인 측면에 집중하여 프로그래밍할 수 있도록 판을 깔아주는 것이 Django와 Flask 같은 웹 프레임워크이다.Django: 마감 시간이 있는 완벽주의자의 프레임워크 Flask: 마감 시간이 없는 완벽주의자의 프레임워크Django vs Flask 대응되는 요소 Django ORM vs SQLAlchemy Form vs flask-wtf Template Engine vs Jinja2 Admin page vs flask-admin south(migrate, makemigrations) vs alembic Middleware vs before_request, after_requrest manage.py vs flask-scripts manage.py test vs unittest or flask-test def view(request) vs flask.requestDjango vs Flask 차이점1. 로그인, 회원가입: 장고에는 기본 유저 모델 및 로그인 기능이 정형화되어 있지만, Flask에서는 구현하는 방법이 천차만별이다. 2. ManyToMany Field: Django에는 ManyToMany Field가 있지만, Flask에서는 매핑해주는 모델을 따로 만들어주어야 한다. 3. get_object_or_404, get_or_create: Flask에는 없는 Django의 편리함 중 하나이다. 4. jsonify, return 문자열: Django에는 없는 Flask의 편리함 중 하나이다. Django에서는 json을 응답하기 위해서 json.dumps()를 통해 바이너리 형태로 만들어준 후, content_type을 명시해서 HttpResponse로 응답해야 했다[1.7 이후에 JsonResponse가 추가되긴 했음]. Flask에서는 ‘return jsonify(data)’ 형태로 간편하게 응답한다. 또한 문자열을 반환하는 것도 가능하다. 5. REST API: 게시판과 같이 정형화된 작업을 할 때에는 Django가 유리하고, 커스텀을 많이 해야하는 작업일 경우에는 Flask가 유리하다. DRF는 커스텀이 까다롭기 때문이다. 6. 정형성: Django는 프로젝트 구조가 보통 정형화되어 있는 반면, Flask는 프로젝트마다 구조가 많이 다르다.기타 유의점 Admin page는 Django의 큰 장점 중 하나로 꼽힌다. 그런데 관리자가 개발자가 아닌 경우, 혹은 관리자 페이지를 많이 수정해야 하는 경우에는 Django나 Flask나 코드양이 비슷하다. Admin page가 장점이 될 수 있는 건 커스텀이 많이 필요없을 때까지만이다. Django와 같은 풀스택 프레임워크를 나중에 하는 것이 좋다는 의견이 있다. 필요성을 느끼지 못한 채 사용하는 도구는 제대로 활용할 수 없기 때문이다. Flask가 가볍다는 것은 쉽다는 게 아니라, 프레임워크가 제공하는 틀이 작고 그만큼 자유도가 높다는 뜻이다. 직접 조립해야 하는 부분이 많으므로 입문자에게 적합하지 않을 수 있다.요약Django에서는 많은 고민거리(세션 저장 위치, ORM, REST, Migration 등)에 대해 일반적인 상황에서 가장 합리적인 방안을 미리 마련해두었다. 따라서 그 고민거리에 대해 직접 고민하기에는 경험과 지식이 부족하다면, Django가 제공하는 기존의 해결 방법들을 사용하고 익히며 웹 프로그래밍의 큰 구조를 파악해나가는 것이 좋을 수 있다. 그에 반해 Flask는 사용자에게 높은 자유도를 주기에, 상황에 맞추어 스스로 더 나은 방법을 고민할 수 있는 사용자에게 적합하다고 볼 수 있다. 이렇게 여러 도구들을 비교하는 과정은 개발자에게 필수적이다. 프로그래밍은 변화와 발전이 빠른 분야인 만큼 더더욱 필수적이다. 자신에게 맞는, 혹은 자신의 상황에 맞는 도구를 찾아가는 고민을 게을리해서는 안 된다.공부 자료 [PyCon 김도현]Django vs Flask, 까봅시다!: https://www.youtube.com/watch?v=cX8n7pRA670 [digrr 개인 블로그]언제 Django를, 언제 Flask를 사용해야 할까?: https://dingrr.com/blog/post/%EC%96%B8%EC%A0%9C-django%EB%A5%BC-%EC%96%B8%EC%A0%9C-flask%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%95%BC-%ED%95%A0%EA%B9%8C" }, { "title": "PyCon - Clean Code, Test, and Refactoring", "url": "/posts/elegant_test/", "categories": "Better Code, Python", "tags": "clean code, test, TDD, refactoring, python, pycon", "date": "2021-12-15 01:00:00 +0900", "snippet": "클린코드, 테스트와 리팩토링사전 개념 코드 악취(code smell): 코드를 읽는 이를 배려하지 않은 코드에서 나타나는 잠재적 문제들을 일컫는 말이다. 보이스카우트 규칙: 언제나 처음 왔을 때보다 깨끗하게 해놓고 캠프장을 떠날 것. 협업을 한다면 처음 받은 코드보다는 더 깨끗한 코드로 만들어야 한다.클린 코드 핵심 가이드 가드클러즈(Guard Clause): 올바르지 않은 value를 체크하여 오류를 반환하는 구문을 위쪽에 배치한다. 이 방법을 통해 인덴트를 줄일 수 있다. NoneObject 활용: 객체가 없을 경우 None이 아닌 NoneObject를 반환하도록 하여 해당 객체가 존재하는지 여부를 따로 파악할 필요가 없도록 한다. [ex. 조건에 맞는 user가 없을 경우, user 객체와 같은 인터페이스를 갖는 user NoneObject를 반환함으로써, 별도로 user의 존재 여부를 파악하는 로직을 쓰지 않아도 되게끔 한다.] ‘not’ syntax sugar 이용 *syntax sugar를 사용하지 않고, 표준 문법을 사용하는 것을 syntax salt라고 한다. 클린 코드에서는 syntax sugar를 사용할 것을 권장한다. NoneObject 활용2: 유효성 오류가 발생하는 경우, 즉시 예외를 throw하기보다는 NoneObject를 반환함으로써, 검사를 마지막에 한 번만 진행할 수 있도록 한다. 삼항 연산자 이용 if else 키워드 사용 시 짧은 조건은 삼항 연산자를 사용한다. 단순한 형태의 if, switch문은 Dict Accessing 형식으로 바꿔준다. 작명 방법: 함수 이름은 snake_case로 지정하고, 행동을 이름의 가장 앞에 명명한다. 명사보다는 동사로써 명확하게 명시해주는 것이 좋다. 주석보단 클린 코드: 주석이 필요할 정도로 복잡한 로직은 별도의 함수로 분리하여, 함수명을 주석 대신 사용한다. 함수를 분리하는 것은 코드의 양을 줄여주고 가독성을 줄여줄 뿐만 아니라, 때로는 다른 클린 코드 패턴을 추가적으로 적용할 수 있게 해준다. 그 밖의 규칙 3줄 이상의 라인이 중복된 코드는 별도의 함수로 분리한다. 주석이 없는 코드가 제일 좋은 코드임을 명심하자. [주석 없이 이해될 수 있는 코드가 좋다는 말이지, 그냥 주석을 없애라는 게 아님] 클래스와 함수에 너무 많은 기능을 주면 안 된다. 많은 기능이 묶여있다면, 기능 별로 함수, 혹은 클래스를 분리하자. 함수의 인자는 4개를 넘으면 안 된다. 복잡한 로직은 캡슐화(별도의 함수로 분리)하고 직관적인 이름을 부여하자. .py 파일 하나에 두 개 이상의 클래스를 정의하지 말자.테스트와 리팩토링테스트 코드가 없다면? 실제 환경에서 동작하는 코드는 생각보다 복잡하다. 그 복잡한 코드는 내부적으로 서로 연결되어 영향을 주고 받는다. 코드의 작은 부분을 수정하더라도, 코드 전체에 큰 영향을 주게 된다. 그렇다고 작은 수정을 할 때마다 일일이 모든 함수를 테스트를 할 수는 없다. 또한 특정 조건 하에서만 발생하는 버그는 감지하기가 매우 어렵다. 그렇기 때문에 개발자는 코드 수정, 혹은 기능 추가에 두려움을 가지게 된다.테스트 종류 Unit Test(단위 테스트): 함수, 메소드의 최소 단위와 각 비즈니스 코드를 체크하는 테스트이다. 파이썬에서는 unittest 모듈을 이용할 수 있다. Integration Test(통합 테스트): 여러 함수, 메소드가 모인 코드의 집합을 전체적으로 체크하는 테스트이다. 실제 사용자 기능 위주의 테스트이다. End-To-End Test(E2E 테스트): 사용자 관점에서 UI 상에서 실제로 테스트해보는 형식의 테스트이다. 사용자의 소프트, 하드웨어 환경까지 고려하기에 가장 복잡하다. E2E 테스트까지는 하지 않는 경우도 많음.테스트 방식 White Box Test: 코드의 내부를 들여다보고 코드를 테스트한다. 보다 세부적인 테스트가 가능하다. Black Box Test: 코드의 내부를 모르는 상태에서 입력 및 출력 값으로 코드를 테스트한다.*user_service.py는 내부 로직을 알고 진행하는 테스트이므로, White Box Test이고, 각각의 API 테스트는 기대값 충족 여부만을 체크하므로 Black Box Test이다. 이처럼 White Box와 Black Box는 서로 배타적인 관계가 아니며 하나의 테스트 내에서 혼용될 수 있다. *Test3은 각각의 API Test(Unit Test)를 엮어 테스트를 진행하였으므로 Integration Test에 속한다.올바른 테스트 디자인 테스트 코드는 가장 작은 함수 단위에서부터 통합 단위로 올라가는 Bottom up 방식으로 작업한다. 세부적인 함수에 대한 테스트를 작성하고, 그 테스트들을 엮어 통합 테스트를 진행하는 형태이다. 리팩토링은 가장 큰 통합 단위에서 함수 단위로 내려가는 Top-Down 방식으로 작업한다. 리팩토링은 side effect를 발생시키므로, 가장 큰 단위에서부터 세부적인 함수로 내려가는 형태가 바람직하다.순수함수가 테스트 작성에 사용하기 적절하다. 순수함수: 함수에 제공된 입력 값에 의해 출력 값이 결정되는 함수이다(하나의 입력 값에 대한 출력 값은 하나뿐이며 외부의 요소에 의해 달라지지 않는다.). 입력 값 외에 상태나 환경에 출력 값이 영향받지 않는다. 순수 함수의 이러한 특징을 참조 투명성(Referential Transparency, RT)라고 한다.*때로는 외부 서버로부터 값을 받아와 테스트를 진행하는 등 불가피하게 비순수함수가 되는 경우가 있다(ex. request 모듈로 외부로부터 정보를 받아오는 경우). 그런 경우에는 가변적인 외부 값을 mocking하여 테스트를 진행한다(의존성 주입). *테스트 함수의 이름은 ‘test_‘로 시작하는 것이 컨벤션이다.TDD(Test Driven Development)테스트 코드를 먼저 작성한 후, 그 테스트 코드를 통과할 수 있는 코드를 작성한다. 그 후 코드의 동작은 차이가 없도록 기능을 유지하면서 코드를 최적화한다. 이 과정에서 테스트 코드에 모두 통과한다는 사실도 유지해야 한다.*TDD(테스트 주도 개발)는 특정 프레임워크나 도구가 아닌 하나의 개발 방법론을 일컫는 말이다.TDD의 필요성 코드 유지보수에 효과적이다. 기존의 코드를 수정하거나 기능을 추가할 때, 자신이 작성한 코드로 인해 다른 부분에 영향이 가지 않았음을 테스트 코드의 피드백을 통해 명확히 알 수 있다. 작성하는 코드에 대한 이해도가 높아지며 깔끔한 코드를 작성하게 된다. 테스트 코드에 맞는 코드를 작성하기 위해서는 깔끔하고 명확한 코드를 작성할 수밖에 없다. 테스트 코드를 통해 개발자의 의도가 드러나므로, 그 자체로 설명 문서가 된다. 순서대로 이어지는 테스트 코드를 보면 코드 의도를 파악하기가 쉬워진다. 개발자가 직접 코드를 검증하는 과정을 축소할 수 있다.*TDD는 코드 생산성 자체를 높여주는 도구가 아니다. 개발 스펙이 자주 변경되거나 개발 속도가 중요한 개발 환경에는 적합하지 않으며, TravisCI, Jenkins 등을 통한 CI 환경이 구성되어 있어야 비로소 TDD의 장점을 극대화할 수 있다.[다른 자료들을 보니 TDD가 수정 사항에 대한 명확한 피드백을 주므로 불확실성이 높은 작업에 오히려 도움이 된다는 의견도 있다.]공부 자료 [pyCon 한성민]우아하게 준비하는 테스트와 리팩토링: https://www.youtube.com/watch?v=S5SY2pkmOy0[TwentyFiveSeven Velog]TDD를 적용해보자 1편: https://velog.io/@xortm854/TDD%EB%A5%BC-%EC%A0%81%EC%9A%A9%ED%95%B4%EB%B3%B4%EC%9E%90-1%ED%8E%B8TDD%EB%9E%80Test-Driven-Development [yohanpro blog]테스트 주도 개발 방법론(TDD)과 필요성: https://yohanpro.com/posts/programming/tdd" }, { "title": "Stack", "url": "/posts/Stack/", "categories": "Computer Science, Data Structure", "tags": "data structure, python, stack", "date": "2021-12-12 01:00:00 +0900", "snippet": "StackStack Methods삽입: push [python에서의 append] 삭제: pop 조회: top 길이: len *python에서 pop은 pop이지만 push는 append인 이유는 push라는 용어가 정립되기 이전에 python이 만들어져 append라는 메소드가 이미 있었기 때문이다. 귀도 반 로섬은 하나의 기능을 하는 두 가지 이상의 메소드가 있길 원치 않았기 때문에 push 메소드를 추가하지 않았다.python class로 스택구현class Stack: def __init__(self): self.items = [] def push(self, item): self.items.append(item) def pop(self): try: return self.items.pop() except IndexError: print(&#39;Stack is empty&#39;) def top(self): try: return self.items[-1] except IndexError: print(&#39;Stack is empty&#39;) def __len__(self): return len(self.items)*python으로 구현한 스택의 메소드는 모두 시간복잡도가 O(1)이다.Case: 계산기 [infix(중위표기법) &amp;gt; postfix(후위표기법) &amp;gt; calculated result] infix 식의 각 요소들을 나누어 리스트로 만든다. infix 식으로 만든 리스트를 postfix 식으로 바꾼다. postfix 식을 계산한다. *(참고 자료)[https://yeahajeong.tistory.com/190]class Stack: def __init__(self): self.items = [] def push(self, item): self.items.append(item) def pop(self): return self.items.pop() def top(self): return self.items[-1] def is_empty(self): return bool(len(self.items) == 0) def __len__(self): return len(self.items)def split_tokens(tokens): result = [] val = 0 val_processing = False for i in tokens: if i in &#39;0123456789&#39;: i = int(i) val = val * 10 + i val_processing = True else: if val_processing: result.append(val) val = 0 val_processing = False result.append(i) if val_processing: result.append(val) return resultdef into_postfix(token_list): result = [] opstack = Stack() priority = { &#39;+&#39;: 1, &#39;-&#39;: 1, &#39;(&#39;: 1, &#39;*&#39;: 2, &#39;/&#39;: 2, &#39;)&#39;: 3 } for i in token_list: if isinstance(i, int): result.append(i) elif i == &#39;)&#39;: while not opstack.top() == &#39;(&#39;: result.append(opstack.pop()) opstack.pop() else: if opstack.is_empty(): opstack.push(i) else: if priority[i] &amp;lt; priority[opstack.top()]: result.append(opstack.pop()) opstack.push(i) else: opstack.push(i) if not opstack.is_empty(): while not opstack.is_empty(): result.append(opstack.pop()) return resultimport numbersdef calculate(postfix): int_stack = Stack() for i in postfix: if isinstance(i, numbers.Number): int_stack.push(i) else: n1 = int_stack.pop() n2 = int_stack.pop() if i == &#39;+&#39;: new_int = n1 + n2 if i == &#39;-&#39;: new_int = n1 - n2 if i == &#39;*&#39;: new_int = n1 * n2 if i == &#39;/&#39;: new_int = n2 / n1 int_stack.push(new_int) return int_stack.top()def cal_tokens(tokens): token_list = split_tokens(tokens) postfix = into_postfix(token_list) result = calculate(postfix) return result공부 자료 [Chan-Su Shin 자료구조]순차적 자료구조 배열과 리스트: https://www.youtube.com/watch?v=Lqd8o7vL2Z8&amp;amp;list=PLsMufJgu5933ZkBCHS7bQTx0bncjwi4PK&amp;amp;index=6 [Chan-Su Shin 자료구조]자료구조 스택 활용 - 계산기 (1/2): https://www.youtube.com/watch?v=G9ujrSGEB4A&amp;amp;list=PLsMufJgu5933ZkBCHS7bQTx0bncjwi4PK&amp;amp;index=9" }, { "title": "Sequential Data Structure", "url": "/posts/Sequential_Data_Structure/", "categories": "Computer Science, Data Structure", "tags": "data structure, python, list, array", "date": "2021-12-11 01:00:00 +0900", "snippet": "Sequential Data Structure(순차적 자료구조)List &amp;amp; Array배열과 리스트는 가장 기본적인 순차적(sequential) 자료구조이다. 파이썬에서는 배열이 아닌 리스트를 이용한다.리스트와 배열의 차이 파이썬 리스트에는 정수 객체의 메모리 주소가 담긴다. 그에 비해 c언어 배열은 메모리에 정수(4byte)가 직접 담긴다. 파이썬 리스트는 append, pop, insert, index 등의 편의를 위한 메소드를 제공한다. 그에 비해 C의 배열에서는 사용자가 필요에 따라 함수를 만들어 사용해야 한다. 파이썬 리스트는 용량이 자동조절된다(dynamic array). 예를 들어 append를 실행할 때에는 추가적인 메모리공간이 필요하므로 용량이 자동으로 커지고, pop을 실행할 때에는 불필요한 공간이 생기므로 용량이 자동으로 작아진다(python이 대신 해줌). 그에 비해 C의 배열에서는 malloc 등의 함수를 이용하여 사용자가 직접 조정해야 한다.순차적 자료구조(Sequential Data Structure) 소개 리스트, 배열 - index로 임의의 원소에 접근하는 형태 스택, 큐, 디큐 - 제한된 접근(삽입, 삭제)만 허용 2-1. 스택: 위에서부터 쌓이는 형태의 자료구조, LIFO(Last In First Out) 가장 나중에 들어온 게 가장 먼저 나간다. 2-2. 큐: 줄서는 형태의 자료구조, FIFO(First In First Out) 가장 먼저 들어온 게 가장 먼저 나간다. 2-3. 디큐: 스택 + 큐, 새로운 자료가 위나 아래로 들어오고 위나 아래로 나간다. 연결 리스트(Linked List): 각각의 자료가 별도의 공간에 저장되어 있되, 각각의 자료에 다음 자료의 주소까지 쌍으로 저장되어 있다(next pointer). 인덱스로 접근할 수 없기 때문에 4번째 자료에 접근하기 위해서는 1, 2, 3번 자료를 모두 거쳐야만 한다. —공부 자료 [Chan-Su Shin 자료구조]순차적 자료구조 배열과 리스트: https://www.youtube.com/watch?v=Lqd8o7vL2Z8&amp;amp;list=PLsMufJgu5933ZkBCHS7bQTx0bncjwi4PK&amp;amp;index=6" }, { "title": "Docker Compose", "url": "/posts/docker_compose/", "categories": "Docker", "tags": "tool, docker, docker compose", "date": "2021-12-10 01:00:00 +0900", "snippet": "Docker Composedocker가 많은 편의를 제공하는 것은 사실이지만, run 명령어로 컨테이너를 실행할 때의 옵션의 개수가 너무 많아 복잡하다는 아쉬운 점이 있다. [볼륨, 포트 설정 등등] 이를 개선하기 위해 docker compose가 등장했다. 컨테이너 실행 시 필요한 옵션을 docker-compose.yml 파일에 미리 적어두어 자동으로 실행되게 할 수 있다. 또한 각각의 컨테이너에 대한 설정 외에도, 컨테이너 간 실행 순서 및 의존성을 관리할 수 있다. 한마디로, docker compose는 여러 개의 컨테이너로 구성된 애플리케이션을 관리하기 위한 오케스트레이션 도구이다.docker-compose 사용법 docker-compose.yml 파일은 프로젝트 루트에 위치해야 한다. docker-compose.yml 파일 내에 아래와 같은 항목을 명시하여 애플리케이션의 환경, 그리고 애플리케이션을 구성하고 있는 서비스를 구체적으로 정의한다.version docker-compose의 맨 위에 파일의 version을 명시한다. exversion: &#39;3&#39; services services 항목의 하위 항목으로 실행하고자 하는 컨테이너들을 정의한다. docker-compose에서는 컨테이너 대신 서비스라는 개념을 사용한다. ex services: db: `!@#!!%$ frontend: `!@#$% volumes 기본적으로는 컨테이너 내에서의 데이터 변경 사항은 저장되지 않으며, 다른 컨테이너 간의 데이터 공유도 불가능하다. 데이터를 컨테이너 내에서 관리하기 때문에 컨테이너 폐기 시 데이터도 같이 폐기되며 데이터가 컨테이너 별로 독립적으로 관리되기 때문이다. 이때 docker volumes 항목을 이용하여 컨테이너 내의 디렉토리와 호스트의 디렉토리를 연결시킬 수 있다. 디렉토리 지정 시 상대 경로로 지정할 수도 있다. exdb: volumes: - ./docker/data:/var/lib/postgresql/data [./docker/data라는 호스트 내의 디렉토리를 컨테이너 내의 디렉토리인 /var/lib~~에 연결] environment 컨테이너의 환경 변수를 설정한다. exenvironment: - POSTGRES_DB=sampledb - POSTGRES_USER=sampleuser build docker build 명령어를 실행할 디렉토리 경로를 설정한다(context). 또한 Dockerfile이 아닌 다른 이름의 파일로 빌드를 하거나, 빌드 인자를 넘겨야 하는 경우에는 하위 항목을 사용하여 구체적으로 설정해준다(dockerfile). exbuild: context: ./app dockerfile: Dockerfile-dev ports 외부에 개방할 포트와 내부에서 열어줄 포트를 설정한다. exports: 8080:8080공부 자료 [생활코딩]생활코딩 Docker 입문수업: https://www.youtube.com/watch?v=Ps8HDIAyPD0 [44bits]도커 컴포즈를 활용하여 완벽한 개발 환경 구성하기: https://www.44bits.io/ko/post/almost-perfect-development-environment-with-docker-and-docker-compose [DaleSeo]Docker Compose 설정 방법: https://www.daleseo.com/docker-compose-file/" }, { "title": "Docker Image", "url": "/posts/docker_image/", "categories": "Docker", "tags": "docker, container, docker image, tool", "date": "2021-12-09 01:00:00 +0900", "snippet": "Docker ImageDocker를 사용하다 보면 이미지를 단순히 pull 받아 사용할 뿐만 아니라 직접 만들어야 하는 상황이 발생한다. 이미지를 직접 만드는 방법을 기록해보고자 한다.image 생성 방법1) commit: 현재 사용하고 있는 컨테이너를 이미지로 만들고 싶을 때 이용한다. 백업의 느낌이다. 2) Dockerfile + build: Dockerfile에 만들고 싶은 이미지의 세부 사항을 기입하고, build 명령어를 통해 이미지를 생성한다. 이미지를 제대로 생성하고자 할 때 사용한다.Case: git이 깔려 있는 ubuntu 이미지 생성1) commit docker pull ubuntu [우분투 이미지를 dockerhub에서 다운받는다.] docker run -it –name -myubuntu ubuntu bash [우분투 이미지로 myubuntu라는 이름의 컨테이너를 생성하고, 그 컨테이너를 배쉬에서 실행시킨다.] 컨테이너 상에 git 설치 docker commit myubuntu hy:git-ubuntu [hy라는 디렉토리에 git-ubuntu라는 이름의 이미지를 생성한다.]2) Dockerfile + build dockerfile에 세부 사항 입력 FROM ubuntu:20.04 RUN sudo apt-get -y update RUN sudo apt-get -y install git docker build -t git-ubuntu [git-ubuntu라는 이름으로 이미지를 생성한다. *t는 tag의 이니셜로, 이미지 이름을 설정한다는 의미이다.]dockerfile 명령문 FROM: 새로운 이미지를 생성할 대 기반으로 사용할 base 이미지 지정한다. WORKDIR: 쉘의 cd 명령문과 같이, 컨테이너 상에서 작업 디렉토리를 전환한다. 이후의 명령문은 해당 디렉토리를 기준으로 실행되게 된다. RUN: 이미지 빌드 과정에서 필요한 커맨드를 실행한다. 보통 이미지 안에 특정 소프트웨어를 설치하기 위해 사용하는 명령문이다. ENTRYPOINT: 이미지를 컨테이너로 띄울 때 항상 실행시킬 커맨드를 지정한다. CMD: 이미지를 컨테이너로 띄울 때 실행시킬 커맨드나 ENTRYPOINT 명령문으로 지정된 커맨드에 넘길 파라미터를 지정한다. EXPOSE: 리스닝 포트 및 프로토콜을 설정한다. 프로토콜을 명시하지 않으면 TCP가 디폴트로 사용된다. COPY: 호스트 컴퓨터에 있는 디렉토리 혹은 파일을 Docker 이미지로 복사한다. 상대 경로를 사용할 때에는 WORKDIR 명령문으로 지정한 경로를 고려해야 한다. ADD: 기본적으로 COPY와 기능이 동일하다. 다만 ADD는 일반 파일뿐만 아니라 압축 파일이나 네트워크 상의 파일도 사용할 수 있다. 특수 파일을 다루는 것이 아니라면 COPY 사용이 권장된다. ENV: 환경 변수를 설정한다. ENV로 설정한 환경 변수는 이미지 빌드 시는 물론이고, 해당 컨테이너에서 돌아가는 애플리케이션에서도 접근할 수 있다. ARG: docker build 커맨드로 이미지 빌드 시 –build-arg 옵션을 통해 넘길 수 있는 인자를 설정한다.image push생성한 이미지를 push를 통해 dockerhub에 올릴 수 있다. docker login docker push 이미지이름[hy/git-ubuntu:1.0.1]공부 자료 [생활코딩]생활코딩 Docker 입문수업: https://www.youtube.com/watch?v=Ps8HDIAyPD0 [DaleSeo]Dockerfile에서 자주 쓰이는 명령어: https://www.daleseo.com/dockerfile/" }, { "title": "Docker Basic Commands", "url": "/posts/docker_basic_commands/", "categories": "Docker", "tags": "docker, container, tool", "date": "2021-12-08 01:00:00 +0900", "snippet": "Docker 기본 커맨드도커 키워드 비유docker hub는 다양한 program을 다운 받는 app store에 비유할 수 있다. image는 설치되는 program에 비유할 수 있다. container는 program이 실행된 구체적인 형태인 process에 비유할 수 있다.docker hub에서 image를 받는 행위를 image를 pull한다고 하고, image를 실행시키는 행위를 image를 run한다고 한다.docker pull기능: docker hub에서 image를 다운받는다. 명령어: docker pull [options] ImageName[:Tag|@DIGEST] docker hub에서 원하는 image를 찾아 상세 페이지로 들어가면 각 image의 이름을 알 수 있다. docker browser를 통해서도 다운 받을 수 있다. ‘docker images’라는 명령어를 통해 현재까지 다운 받은 image 리스트를 확인할 수 있다.docker run기능: image에 기반하여 container를 생성한다. 명령어: docker run [options] ImageName [command] [arg…] ex. docker run –name webserver -p 8080:80 httpd [httpd image를 이용하여 webserver라는 이름으로 container를 만들고, 8080포트를 container의 80포트랑 연결시킨다.] docker run -i: i는 interactive의 이니셜이다. container와 상호적으로 주고 받겠다는 뜻으로, attach 없이도 STDIN으로 유지하겠다는 뜻이다. docker run -t: t는 tty의 이니셜이다. 리눅스에서 tty는 콘솔 및 터미널 환경을 의미한다. -t 옵션은 터미널과 같은 환경을 조성해준다. docker run -d: d는 detach의 이니셜이다. container를 백그라운드에서 실행시킨다.docker ps기능: 생성된 container 정보를 조회한다. 명령어: docker ps docker ps -a: 종료된 container까지 포함하여 조회한다.docker stop기능: 실행중인 container를 중단시킨다. 명령어: docker stop ContainerNamedocker start기능: 종료했던 container를 다시 시작시킨다. [새로 container를 생성하는 것이 아니라 이전에 생성했다가 스탑시킨 container를 다시 실행시키는 것] 명령어: docker start ContainerNamedocker start로 실행시킬 때는 터미널에 로그가 따로 출력되지 않기에 따로 명령어를 입력해야 한다. docker logs ContainerName: 해당 container의 로그 출력 docker logs ContainerName: 해당 container의 로그 지속적 출력docker rm기능: container를 삭제한다. 명령어: docker rm [options] ContainerName [container…] 단, 현재 실행 중인 container는 삭제할 수 없으므로 docker stop으로 중지시킨 후 삭제한다. 혹은 ‘—force’ 옵션를 이용한다. image 삭제의 경우에는 ‘docker rmi ImageName’ 명령어를 사용한다. [혹은 image prune이라는 명령어를 이용한다.]docker exec기능: 실행 중인 컨테이너에 명령을 내린다. 명령어: docker exec ContainerName Command ex. docker exec -it ContainerName /bin/sh[/bin/bash] [실행 중인 컨테이너 bash 실행]docker attach기능: 실행 중인 컨테이너에 접속한다. 명령어: docker attach ContainerName호스트와 container의 파일 시스템 연결container의 효용은 필요할 때 손쉽게 만들고, 필요 없어지면 얼마든지 없앨 수 없다는 데에 있다. 그런데 container를 삭제할 때마다 container의 소스코드가 날아가면 되겠는가? 그래서는 안 되기 때문에 호스트와 container가 상호 연결될 필요가 있다. 파일 수정은 호스트에서 하고, 실행 환경 관련해서는 container에 맡기는 게 이상적일 것이다. 그것을 위한 명령어 예시: docker run -p 8888:80 -v ~/Desktop/htdocs:/usr/local/apache2/htdocs/ httpd [‘8888포트를 80포트로 매칭시키고, ‘~/Desktop/htdocs’과 ‘/usr/local/apache2/htdocs/’를 매칭시켜 httpd container를 만들어라’라는 뜻]공부 자료 [생활코딩]생활코딩 Docker 입문수업: https://www.youtube.com/watch?v=Ps8HDIAyPD0 [snowturtle93]Docker Run 옵션: https://snowturtle93.github.io/posts/Docker-Run-%EC%98%B5%EC%85%98/" }, { "title": "Docker Basic Concept", "url": "/posts/docker_basic_concept/", "categories": "Docker", "tags": "docker, container, tool", "date": "2021-12-07 01:00:00 +0900", "snippet": "Docker 기본 개념Docker를 왜 쓰는 걸까?본격적으로 프로그래밍을 하기 이전에 환경 세팅을 하는 것이 여간 까다로운 게 아니다. 운영체제마다 적합한 소프트웨어(웹서버, 데이터베이스)의 종류 및 버전이 제각기 다르기 때문이다. 이런 것에 얽매이지 않기 위해 운영체제를 추가로 설치하는 것은 리소스 낭비가 지나치다. 그리하여 운영체제를 별도로 설치하지 않고 가볍게 독립적인 환경을 마련해주기 위해 컨테이너 개념이 등장했다. 필요한 라이브러리와 실행 파일만 설치하여 소프트웨어를 (프로세스 별로) 다양한 환경에서 똑같이 사용할 수 있게 해주는 것이 컨테이너이다. 그리고 리눅스 컨테이너 서비스 중 가장 널리 알려진 것이 Docker이다! Docker가 ‘리눅스’ 컨테이너 서비스이긴 하지만 다른 운영체제를 사용해도 문제가 없다. 다른 운영체제에서는 Docker가 알아서 가상머신을 만들고 그 위에 리눅스를 설치해주기 때문이다(Hypervisor 활성화). 하지만 이 때문에 다른 운영체제 환경에서는 리눅스 환경에서 Docker를 사용할 때에 비해 성능이 다소 저하된다.*Docker의 원래 뜻은 부두에서 컨테이너를 다루는 부두 노동자를 가리키는 단어이다. *Hypervisor: 가상 머신(VM)을 생성하고 구동하는 소프트웨어 *컨테이너는 쉽게 말해 격리된 환경에서 실행되는 프로세스이다.VM 가상화 vs Docker 컨테이너VM 가상화 플랫폼의 경우에는 Host OS 위에 가상화를 위한 엔진 + Guest OS를 올려야 한다. 그렇기에 Guest OS와 Host OS가 완벽히 분리되는 장점이 있지만, OS 위에 또 다른 OS를 올리기 때문에 무겁고 느리게 동작한다. 이에 반해 컨테이너 기반 가상화는 Host의 커널을 공유하는 형태로, docker 엔진 위에 필요한 바이너리만 올려서 어플리케이션을 동작시킨다. 가상머신과 컨테이너 가상화는 호스트의 환경과 다른 환경을 제공해준다는 점에서는 비슷해 보이지만, 가상머신은 os 단위이고, 컨테이너는 프로세스 단위이다. 가상머신은 하드웨어를 통째로 소프트웨어로 재구현한다. 그에 반해 컨테이너는 하나의 프로세스에 불과하다. 컨테이너는 호스트의 실행 환경과 독립적인 환경에서 돌아가는 프로세스이다. 컨테이너 기반 가상화가 OS 가상화보다 무조건적으로 좋은 것은 아니다. OS 가상화는 컨테이너 기반 가상화보다 더 높은 격리 레벨을 지원하고, 그만큼 보안적인 면에서 유리하다. 또한 커널을 공유하지 않아 멀티 OS가 가능하다는 장점이 있다. 그럼에도 Docker가 가장 인기 있는 이유는 성능 향상, 뛰어난 이식성, Scale Out을 쉽게 할 수 있는 유연성에 있다.왜 굳이 리눅스에서 돌려야 할까?Docker의 컨테이너는 리눅스 커널이 제공하는 몇 가지 기능들에 의존하고 있다. chroot(독립 공간 형성), namespace(isolate 기능), cgroup(필요한 만큼 하드웨어 지원), 이 세 가지 기능이 있어야 Docker를 사용할 수 있기 때문에 리눅스에서만 돌릴 수 있는 것이다. Docker 엔진은 리눅스 커널에서 제공하는 이 세 가지 기능을 Docker 플랫폼에서도 사용할 수 있게 해주는 역할을 수행한다.Docker 컨테이너의 개략적 구조host는 Docker를 돌리는 사용자의 실제 컴퓨터 환경이고, container는 docker로 생성한 가상의 환경이다.공부 자료 [생활코딩]생활코딩 Docker 입문수업: https://www.youtube.com/watch?v=Ps8HDIAyPD0 [44bits.io]Docker(Docker) 입문편: https://www.44bits.io/ko/post/easy-deploy-with-docker" }, { "title": "Git Flow", "url": "/posts/git_flow/", "categories": "Git", "tags": "git, 협업, tool", "date": "2021-12-06 15:00:00 +0900", "snippet": "Git Flow: 깃을 잘 사용하기 위한 한 가지 방법깃의 커맨드를 아는 것만으로는 깃을 잘 사용한다고 할 수 없다. 깃의 기능을 십분 활용하기 위해서는 전략이 필요하다. 이 세상에는 많은 깃 브랜치 전략이 존재한다. 우선 그 중 가장 대표적인 ⭐️Git Flow⭐️에 대해 기록하고자 한다.브랜치 종류1) master: 배포 가능한 상태만을 관리하는 브랜치. 즉, 사용자들이 이용한, 혹은 이용할 프로그램을 담고 있는 브랜치. 2) develop: 개발이 이뤄지는 통합 브랜치. 각 팀원들이 작업한 내역이 합쳐지는 공간이다. 3) feature: 개발 과정에서 기능 단위로 나눠지는 브랜치. ‘feature/#이슈번호’와 같은 형식으로 작명된다. 하나의 기능이 완성되면 develop 브랜치로 병합된다. feature 브랜치는 보조 브랜치로, 개발자의 저장소에만 존재하며 origin에 push하지는 않는 것이 보통이다. 4) release: 배포를 위한 최종 버그 수정을 수행하는 브랜치. 배포 가능한 상태가 되면, master 및 develop 브랜치로 병합한다. 5) hotfix: 배포 이후 긴급 수정사항이 발생할 때 이용하는 브랜치. 중심이 되는 메인 브랜치는 master와 develop이며, 필요에 따라 생성되는 feature, release, hotfix 브랜치는 병합 이후 삭제한다.절차1) master 브랜치로부터 develop 브랜치를 파생시킨다. 2) develop 브랜치로부터 각 기능 별로 feature 브랜치를 파생시킨다(ex. feature-login). 3) feature 브랜치에서 개별 기능에 대한 작업이 끝나면 그 내용을 develop 브랜치에 병합시킨다. 4) 작업이 마무리되고 사용자에게 서비스를 제공하는 순간이 거의 다가오면 develop 브랜치로부터 release 브랜치를 파생시킨다. 5) release 브랜치에서는 버그 수정과 관련된 작업을 수행한다. 버그를 잡으며 틈틈이 수정 사항을 develop 브랜치에 병합시킨다. 6) release 브랜치에서 충분히 버그를 잡고 테스트까지 마쳤다면, 마침내 master 브랜치로 병합시킨다. 이때 tag를 이용하여 버전을 기록한다. 7) 완성된 프로그램을 서버에 업로드 하거나 다운로드 받을 수 있게 하는 등, 사용자가 이용할 수 있게 한다. 8) 사용자에게 제공한 이후의 수정 사항이 발생하면, master 브랜치로부터 hotfix 브랜치를 파생시켜 버그를 잡고, 수정 사항을 master 브랜치에 병합시킨 뒤 tag로 버전을 명시한다. 그 후, develop 브랜치에까지 병합시킨다.공부 자료 [생활코딩]지옥에서 온 Git: https://youtube.com/playlist?list=PLuHgQVnccGMA8iwZwrGyNXCGy2LAAsTXk [Plus Ultra tistory]협업을 위한 Git Flow 설정하기:https://overcome-the-limits.tistory.com/entry/%ED%98%91%EC%97%85-%ED%98%91%EC%97%85%EC%9D%84-%EC%9C%84%ED%95%9C-Git-Flow-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0" }, { "title": "Git Branch", "url": "/posts/git_branch/", "categories": "Git", "tags": "git, 협업, tool, branch", "date": "2021-12-06 14:00:00 +0900", "snippet": "Git Branch나무의 가지에서 따온 말[개발에서는 root, trunk, branch 등등 식물에서 말을 많이 따옴]브랜치가 제공하는 편의1) 깔끔한 로그 관리: 하나의 기능을 제작하는 과정에서 한 번에 완성시킬 수 있는 것이 아닌 이상, commit은 많이 발생할 것이다. 그런데 그 많은 commit이 모두 메인 저장소의 log에 남는다면, 이후에 버전 관리가 아주 어려워질 것이다. 브랜치는 개발 과정에서는 commit을 많이 하다가도, 메인 저장소에는 큼직하고 유의미한 수정 사항만을 저장할 수 있게 해준다. 2) 협업 용이: 협업하는 과정에서, 하나의 파일의 같은 부분을 두 사람이 동시에 수정하는 상황이 발생하면 충돌이 발생한다. 개발 도중 이러한 충돌이 자주 발생한다면 불편이 상당할 것이다. 하지만 브랜치를 분리하여 협업을 진행한다면 충돌을 자주 경험하지 않고 개발을 해나갈 수 있다. 3) 용도 별 저장소 분리: 개발~완성의 과정에서 용도 별로 별도의 저장소가 필요한 경우가 있다[반드시 필요하지 않더라도 있으면 훨씬 편리할 수 있다.]. 예를 들면, Github를 이용하여 배포 자동화하는 경우가 있다. Github에 Push하면 자동으로 재배포되도록 설정해두었다면, 하나의 브랜치만으로는 충분하지 않다. 왜냐하면 변경사항마다 배포한 사이트에 반영이 된다면, commit에 에러가 포함되었을 경우, 그것이 곧바로 배포한 사이트에까지 반영되기 때문이다. 이런 상황에서 브랜치를 나누어 용도 별로 여러 개의 저장소를 마련해둔다면 많은 문제 사항이 해결된다.브랜치?브랜치는 독립적으로 어떤 작업을 진행하기 위해 등장한 개념이다. 각각의 브랜치는 다른 브랜치의 영향을 받지 않기 때문에 동시에 여러 작업이 진행될 수 있다. 다양하게 만들어진 브랜치는 다른 브랜치와 병합(Merge)함으로써 작업한 내용을 다시 한 곳으로 모을 수 있다. 여러 명이 동시에 작업을 할 때 메인 브랜치에서 자신의 작업 전용 브랜치를 만들어 각자 작업한 후, 작업이 끝난 사람은 자신의 브랜치의 변경 사항을 메인 브랜치에 적용한다. 이렇게 브랜치를 이용하면, 각자가 다른 사람의 작업에 영향을 받지 않고 독립적으로 작업할 수 있으며, ‘작업 단위’, 즉 브랜치로 그 작업의 기록을 중간중간 남기기 되므로 문제가 발생했을 때 원인이 되는 작업을 찾아내기 쉬워진다.[브랜치가 여러 개여도 각 변경 사항만 저장하기에 추가적인 저장소 사용은 크게 없다.]브랜치 생성 및 이동 git branch: 현재 생성된 브랜치 목록을 확인한다. [default는 master] git branch 브랜치이름: 브랜치 생성 git branch -d 브랜치이름: 브랜치 삭제 git checkout 브랜치이름: 해당 브랜치로 이동한다. git checkout -b 브랜치이름: 브랜치 생성 후 체크아웃 git checkout 커밋번호: 해당 커밋으로 체크아웃[해당 커밋 당시의 상세한 내용을 알아야할 때 사용]병합 git merge 브랜치이름[병합당할브랜치]: 병합할 브랜치(메인 브랜치)로 체크아웃한 후 명령어를 실행한다.merge를 위한 툴(kdiff3): https://www.youtube.com/watch?v=0RqbZt_TZkY&amp;amp;list=PLuHgQVnccGMA8iwZwrGyNXCGy2LAAsTXk&amp;amp;index=31 git rebase 브랜치이름: base(파생된 브랜치)를 바꾼다는 의미이다. 병합될 브랜치의 가장 최근 커밋을 base로 바꾼다. merge와 마찬가지로 두 브랜치를 병합하지만, merge는 브랜치들이 병렬 상태로 유지되는 반면, rebase는 브랜치들이 수평적으로 합쳐진다. rebase는 커밋의 역사를 한 눈에 알아보기 좋다는 장점이 있지만, 위험한 측면이 있으니 사용에 유의해야 한다.임시 저장 git stash: 어떤 작업을 하던 도중 다른 브랜치에서 다른 작업을 해야 하는 상황이 온다면, 하던 작업을 버릴 수도 없고 커밋할 수도 없는 상황이 벌어진다. 그때 변경 사항[git 저장소에서 관리하고 있는 파일들만을 대상으로 함]을 어딘가에 숨겨둘 수 있게 해주는 명령어이다. 변경 사항은 저장되지만, 스테이지 상태까지는 그대로 저장되지 않는다. git stash apply [stash 이름]: stash를 working directory에 불러내는 명령어이다(이름을 명시하지 않으면 가장 최근 stash 불러냄). git stash drop [stash 이름]: stash를 삭제한다(이름을 명시하지 않으면 가장 최근 stash 삭제). [stash 내역은 명시적으로 삭제하기 전까지는 삭제되지 않는다.] git stash pop: git stash apply와 git stash drop을 한 번에 수행하는 명령어이다. git stash list: stash를 목록으로 확인한다.*stash는 ‘(안전한 곳에) 넣어 두다[숨기다]’라는 뜻이다.충돌 해결같은 파일일지라도 다른 부분을 수정하면 충돌이 일어나지 않는다. 하지만 같은 파일, 그리고 같은 부분을 수정하면 충돌이 발생하여 auto-merging이 불가능하다. 이때는 수정사항을 직접 비교하여 merge 시켜줘야 한다(stash도 마찬가지).&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEADfunction a(master) {======function b(exp) {&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; exp충돌이 발생하면 위와 같이 ‘=====’을 기준으로 하여 비교해서 보여준다. [파일 내용 자체가 위의 내용처럼 변한다.] HEAD 아래쪽은 HEAD 브랜치, 즉 현재 체크아웃한 브랜치에서의 수정 사항이고, exp 위쪽은 exp라는 브랜치에서의 수정 사항이다.fucntion a(master, exp) {위와 같이, 최종적으로 수정하고 싶은 부분만 남겨두고 저장한 후, git add 및 commit을 하면 성공적으로 merge가 된다. [rebase의 경우 동일한 과정을 수행하고, git rebase —continue 명령어를 실행하면 된다.]*참고로 HEAD가 가리키는 브랜치가 현재 브랜치이다.공부 자료 [생활코딩]지옥에서 온 Git: https://youtube.com/playlist?list=PLuHgQVnccGMA8iwZwrGyNXCGy2LAAsTXk [누구나 쉽게 이해할 수 있는 Git 입문]브랜치(Branch): (https://backlog.com/git-tutorial/kr/stepup/stepup1_1.html) [제로초]Git 브랜치(Branch) 관리: https://www.zerocho.com/category/Git/post/582342a73fbde700178771f5" }, { "title": "Git Basic Commands", "url": "/posts/git_basic_commands/", "categories": "Git", "tags": "git, 협업, tool", "date": "2021-12-06 13:00:00 +0900", "snippet": "깃 기본 명령어깃이 제공하는 편의1) 편리한 버전 관리: 원할 때마다 지금의 개발 현황을 기록할 수 있고, 언제든 그 상태로 다시 돌아갈 수 있다. 2) 협업 용이: Git은 여러 사람이 한 프로젝트를 작업하기 좋은 환경을 마련해준다. 특히 branch는 여러 사람이 동시에 작업하는 것을 가능하게 해주며, Git과 함께 이용하는 서비스인 Github에서는 Fork, Pull Request, Issue 등 협업을 위해 사용할 수 있는 다양한 기능을 추가로 제공해준다.시작 git init: 디렉토리를 깃의 제어 하에 두기 위한 시작 명령어. ‘.git’ 디렉토리가 생성되며, 그 안에 git 관련 정보들이 저장된다.설정 git config —global user.name 이름 git config —global user.email 이메일저장(추적?) git add 파일명: git이 파일을 track하게 하기 위한 명령어. 해당 파일을 커밋 대기 상태로 만든다[staging area에 올린다]. 버전 관리에 포함하고자 하는 파일을 이 명령어를 통해 추가한다. 이 add 명령어 덕분에 한 번에 여러 작업을 해도 각각의 작업 내역을 다른 커밋으로 저장할 수 있다. git commit: git 핵심 명령어. 변화local repository에 올리는 명령어. 유의미한 변화를 기록할 때 사용하는 명령어이다. 변화의 역사가 모두 기록되기 때문에 언제든지(해당 커밋을 명시적으로 삭제하지 않는 이상) 원하는 커밋으로 되돌아갈 수 있다.git commit 옵션 git commit -a(all): add를 따로 하지 않아도 변경사항을 커밋할 수 있다. [단, 버전 관리가 되고 있지 않은 파일은 한 번은 add 해줘야 함] git commit -m(message): 커밋 파일을 따로 작성하지 않고, 메시지만 적어서 커밋을 한다. git commit -am과 같이 두 옵션을 함께 사용할 수도 있다. git commit —amend: 커밋을 수정한다.기록 조회 git log: 커밋 내역을 확인한다.git log 옵션 -p: 커밋 간의 변경 사항을 보다 자세히 확인할 수 있다. —branches: 브랜치 정보를 같이 확인할 수 있다. —decorate: 각 브랜치 어떤 커밋을 가리키는지 확인할 수 있다. —graph: 브랜치가 여러 갈래로 나뉜 것을 시각적으로 확인할 수 있다. —oneline: 한눈에 보기 편하게 해준다. git reflog: reset된 커밋까지 포함해서 볼 수 있다. git diff: 현재 stage area에 올라가지 않은 파일들과 staging area에 올라간 파일들을 비교하여 보여준다. working directiory와 index의 내용을 비교 [git add하기 전에 마지막으로 점검하기 위한 커맨드] git diff 커밋번호1[브랜치명1]..커밋번호2[브랜치명2]: 두 커밋[브랜치] 사이의 변화를 보여준다.되돌리기 git reset 커밋번호: 해당 커밋을 가장 최신 커밋으로 만들고, 그 이후의 커밋은 없앤다[사실은 남아있음]. 단, 원격 저장소에 반영된 내용은 건드리면 안 되고, 로컬에서의 변경사항만 되돌려야 한다. [커밋번호 생략 시에는 가장 최근 커밋으로 적용] git reset ORIG_HEAD: 가장 최근 커밋을 되돌린다.reset을 다시 되돌리기git reset 옵션 —soft: respositoy까지 반영. [commit에 해당] —mixed: : index(staging area)까지 반영. [add에 해당] —hard: working directory까지 반영. git revert: 커밋을 취소하면서 새로운 버전을 만드는 것.공부 자료 [생활코딩]지옥에서 온 Git: https://youtube.com/playlist?list=PLuHgQVnccGMA8iwZwrGyNXCGy2LAAsTXk" }, { "title": "Cardinality Constraints(RDB 관계 유형)", "url": "/posts/Cardinality_Constraints/", "categories": "Database, RDB", "tags": "rdb, cardinality, relationship", "date": "2021-12-05 13:00:00 +0900", "snippet": "RDB 관계 유형(Cardinality Constraints)1. One-to-Many Relationship(일대다 관계)가장 일반적인 유형의 관계로, 한 테이블의 한 개의 row가 다른 한 테이블의 한 개 이상의 row와 엮인다. 예를 들면 한 명의 작성자가 여러 글을 작성하는 하는 경우이다. 한 명의 작성자는 여러 개의 글을 쓸 수 있지만, 하나의 글은 여러 작성자에 의해 작성될 수 없다. 참조하는 쪽의 테이블에서는 참조되는 데이터가 여러 번 반복해서 참조될 수 있다. 2. Many-to-Many Relationship(다대다 관계)한 테이블의 한 개 이상의 row가 다른 한 테이블의 한 개 이상의 row와 엮인다. 예를 들면, 여러 학생이 여러 수업에 등록하는 경우이다. 한 명의 학생은 하나 이상의 수업을 들을 수 있으며, 하나의 수업은 한 명 이상의 학생을 포함할 수 있다. 소비자가 상품을 장바구니에 담는 경우도 이러한 관계에 해당한다. 그런데, 하나의 row(데이터)가 특정 column에서 여러 항목을 참조할 수는 없다. 따라서 junction(or linking) table이라 불리는 새로운 테이블을 만들어 관계를 형성한다. 두 개의 테이블을 각각 다른 column으로서 참조하는, 오직 둘의 관계를 나타내는 용도로만 쓰이는 테이블을 만드는 것이다. 실무에서는 이와 같은 다대다 관계를 사용하지 않는 것이 좋다. 왜냐하면 서비스가 확장함에 따라, 혹은 기능이 추가됨에 따라 junction table 자체에 주문시간 혹은 수량과 같은 추가적인 데이터가 들어가야 할 필요성이 생길 수 있기 때문이다. junction table은 오직 서로 다른 두 테이블의 데이터를 mapping 해주는 역할만 하기에 적합하지 않다. 따라서 다대다 관계를 나타낼 때에는, 별도의 연결용 엔티티를 생성하여 junction table을 엔티티로 승격시키는 것이 좋다.3. One-to-One Relationship(일대일 관계)한 테이블의 한 개의 row가 다른 한 테이블의 한 개의 row와 엮인다. 이와 같은 관계는 간혹가다 존재하긴 하지만, 흔히 쓰이지는 않는다. 왜냐하면 한 개의 데이터에 한 개의 데이터가 mapping 되는 것이면, 그냥 둘을 하나로 합치면 되기 때문이다.이와 같이 몇대몇 관계인지 나타내는 Cardinality Contraints 외에도, 하나 이상의 participantion이 있어야 하는지 아닌지(django로 치면, null=True인지 아닌지)에 따라 구분짓는 Existence Dependency Constraints도 있다.공부 자료 Database - Fundamentals: https://medium.com/omarelgabrys-blog/database-fundamentals-part-2-b841032243ac 다대다 관계: https://ict-nroo.tistory.com/127" }, { "title": "Big-O", "url": "/posts/Big-O/", "categories": "Computer Science, Data Structure", "tags": "python, cs, 자료구조", "date": "2021-12-04 13:00:00 +0900", "snippet": "Big-O 표기법시간 복잡도를 어떤 식으로 간단히 표현하는 게 좋을끼?Big-O는 시간 복잡도를 증가율의 관점에서 표현한다. 증가율을 대표하는 것은 최고차항의 차수이다. Big-O는 최고차항을 제외한 항, 혹은 최고차항의 계수는 고려하지 않는다.예시2n-1, 5n+3 … =&amp;gt; O(n) (빅오 엔) 4n^2+10, 12n^2+12 =&amp;gt; O(n^2) (빅오 엔 제곱)Big-O 정리1) 최고차항만 남긴다.2) 최고차항의 계수(상수)는 생략한다.3) O(n^최고차항의 차수) 꼴로 나타낸다.[계산 횟수가 입력 크기 n과 무관하다면, 즉 상수항만 존재한다면 O(n^0), 즉 O(1)로 표현한다.]Big-O 효율성 비교" }, { "title": "Time Complexity 2", "url": "/posts/TimeComplexity2/", "categories": "Computer Science, Data Structure", "tags": "python, cs, 자료구조", "date": "2021-12-03 13:00:00 +0900", "snippet": "알고리즘의 시간 복잡도2(time complexity)알고리즘의 실행 시간을 어떻게 구해야 할까?(1) 모든 입력에 대한 기본 연산 횟수의 평균 사실 알고리즘의 실행 시간은 input의 사이즈에 따라 달라진다. 그렇다면 모든 입력에 대한 기본 연산 횟수를 더한 후 평균을 내는 것이 좋을 것 같아 보인다. 하지만 고려해야 할 입력이 너무나도 많아 쉽지 않아 보인다.(2) 가장 오래 걸리게 하는 입력에 대한 기본 연산 횟수 실행 시간이 가장 길어지는 입력(worst input)에 대한 기본 연산 횟수를 측정한다. 이렇게 측정된 시간 복잡도를 worst time complexity라고 한다. 모든 입력을 반영한 것이 아니기에 정확성의 측면에서 한계가 있다. 하지만 측정이 용이하고, 어떤 입력이 오더라도 wtc보다 수행 시간이 길지 않다는 사실만큼은 보장할 수 있다. 보통 알고리즘 수행 시간은 (2)번 방식으로 측정한다. 즉, “알고리즘 수행 시간 == 최악의 입력에 대한 기본 연산 횟수”이다. 또한 보통 알고리즘 수행 시간은 n(input size)에 관한 식으로 표현된다.예시1번algorithm sum1(A, n): sum = 0 (1) for i = 0 to n-1 do if A[i] % 2 == 0: (2) sum += A[i] (3) return sum위의 식에서 최악의 입력을 생각해보면, 연산문 (3)이 모든 i에 대해 실행되는 경우이다. 따라서 모든 i가 짝수인 경우가 worst input이다. 이때의 기본 연산 횟수를 계산해보면, (1)에서 1회, (2)에서 ‘%(산술 연산)’ 1회, ‘==(비교 연산)’ 1회를 총 n번 반복하므로 2n회, (3)에서 ‘+(산술 연산)’ 1회, ‘=(대입 연산)’ 1회를 총 n번 반복하므로 2n회, 이를 모두 더하면 총 4n + 1이다. 따라서 최악의 입력은 A의 요소가 모두 짝수일 경우이고, 이때의 시간 복잡도 T(n) = 4n + 1이다.2번algorithm sum2(A, n): sum = 0 for i = 0 to n-1 do for j = i to n-1 do sum += A[i] * A[j] return sum위의 알고리즘의 시간 복잡도를 n에 대한 식으로 나타내면?3/2n(n-1) + 1다음 시간 - Big-O 1번 알고리즘의 수행 시간은 n에 관한 식인 반면, 2번 알고리즘의 수행 시간은 n^2에 관한 식이다. 즉 1번 알고리즘은 수행 시간이 n에 비례하고, 2번은 수행 시간은 n^2에 비례한다. 1번에 비해 2번이, n의 크기에 훨씬 민감하게 반응한다. 다음 시간엔 이러한 시간 복잡도를 보다 간단하게 나타낼 수 있는 법에 대해 배울 것이다." }, { "title": "Time Complexity 1", "url": "/posts/TimeComplexity1/", "categories": "Computer Science, Data Structure", "tags": "python, cs, 자료구조", "date": "2021-12-02 13:00:00 +0900", "snippet": "알고리즘의 시간 복잡도 1(time complexity)알고리즘의 성능을 좌우하는 요소 소프트웨어 및 하드웨어 환경에 따라 같은 알고리즘이 다른 성능을 발휘한다. 입력값의 크기에 따라 상이한 성능을 보인다.공부하는 과정에서는 위와 같은 요소를 배제한다. Virtual Machine + Pseudo Language + Pseudo Code를 상정하여 모든 알고리즘이 같은 환경에서 실행된다고 가정한다.공부하는 과정에서 상정하는 3가지 요소(1) Virtual Machine(가상 컴퓨터) 가상 컴퓨터: Turing Machine, RAM(Random Access Machine) RAM == CPU + Memory + 기본 연산가상 컴퓨터의 기본 연산은 모두 같은 단위 시간이 걸린다고 가정한다.기본 연산 배정, 대입, 복사 연산: a = b 산술 연산: +, -, *, / [나머지, 버림, 반올림 등의 연산은 기본 연산에 포함되지 않지만, 이 수업 내에서는 기본 연산으로 가정] 비교 연산: &amp;gt;, &amp;gt;=, &amp;lt;, == … 논리 연산: AND, OR, NOT 비트 연산: bit-AND, bit-OR, bit-NOT(2) Pseudo Language(가상 언어) RAM 모델의 기본 연산을 표현할 수 있는 가상의 언어이다. 배정, 산술, 비교, 논리, bit-논리, 반복문, 함수와 같은 기본 연산을 표현할 수 있는 언어이면 된다.(3) Pseudo Code(가상 코드) RAM 모델에서 돌아가는 코드이다. 실제로 실행되어야 하는 코드가 아니라, 논리적인 설명이 가능한 형태이면 된다.다음 시간 - 시간 복잡도 2 기본 연산의 횟수가 늘어날수록 실행 시간이 늘어나는 것이고, 그 말인즉슨 성능이 안 좋아지는 것이다. 즉, 기본 연산의 횟수에 의해 알고리즘의 성능이 측정되는 것인데, 연산이 복잡해질수록 일일이 연산 횟수를 측정하는 것이 어려워진다. 그렇다면 알고리즘의 수행 시간은 어떻게 측정해야 할까?" } ]
